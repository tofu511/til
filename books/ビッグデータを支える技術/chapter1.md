# ビッグデータの基礎知識

## 1.1 [背景]ビッグデータの定着
- ビッグデータの扱いが難しい理由
  - データの分析手法を知らない
  - データ処理に手間と時間がかかる

- Hadoop
  - 多数のコンピュータで大量のデータ処理を行うためのシステム
  - GoogleのMapReduceを参考に作られた

- NoSQL
  - 伝統的なRDBの制約を取り除くことを目指したデータベースの総称
  - 様々な種類がある
    - キーバリューストア(KVS)
    - ドキュメントストア
    - ワイドカラムストア
    
## 1.2 ビッグデータ時代のデータ分析基盤
- ビッグデータ技術とは、分散システムを活用しながらデータを次々と加工していく一連の仕組み

#### データパイプライン
- 次々と受け渡されていくデータによって構成されるシステムのこと
- 徐々に複雑化していき、どう組み合わせるかが問題になる

#### データ収集
- パイプラインにデータを転送する方法は大きく2つある
  - バルク型
    - 既に何処かにあるデータをまとめて取り出す方法
  - ストリーミング型
    - 次々と生成されるデータを絶え間なく送り続ける方法

#### ストリーム処理とバッチ処理
- 受け取った処理をリアルタイムに処理することをストリーム処理と呼ぶ
  - 時系列データベースはリアルタイム処理に向いている
- ストリーム処理は長期的なデータ分析には向かない
  - 処理すべきデータ量が膨大になってしまう

#### 分散ストレージ
- 多数のコンピューターとディスクからなるストレージシステムの総称
- 集めたデータは分散ストレージに格納される
- オブジェクトストレージ(S3など)かNoSQLデータベースが使われる

#### 分散データ処理
- 分散ストレージに蓄えたデータを処理するには分散データ処理のフレームワークが必要
- ビッグデータをSQLで処理するためには二つの方法がある
  - クエリエンジンを導入する
  - 外部のデータウェアハウス製品を利用する
    - データウェアハウスに入れるためにETL(extract-transform-load)プロセスが必要になる

#### ワークフロー管理
- データパイプライン全体の動作管理するための技術をワークフロー管理と呼ぶ

### データウェアハウスとデータマート
- データウェアハウスは「大量のデータを長期保存する」ことに最適化されている
- データウェアハウスは少量のデータを頻繁に読み書きするのには向いていない
- データウェアハウスから見てログなどのローデータ(raw data,生データ)を保存してあるところをデータソースと呼ぶ
- データウェアハウスから必要なデータを取り出して、データ分析などに使う場合、データマートを構築する
